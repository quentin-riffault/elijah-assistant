{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the correct action according to text query (command)\n",
    "\n",
    "Our issue is to find an action that is coherent with a command that is given to the model. How to find a correct answer ? Let's take the example of Alexa. Alexa probably uses a neural-network model in order to get a coherent response. This can work with huge neural networks on cloud-driven architectures. However, on a simpler architecture, it may seem harder to do so. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Method 1 : Incremental database learning\n",
    "\n",
    "This method uses a command database in order to find the adequate answer. The user will give a command string to the model and the model will have to answer. If the answer is not what the user wants, then the user associates an action to his command and the database is updated.\n",
    "\n",
    "![](commands-doc/IDL-flow1.svg)\n",
    "\n",
    "### Query preprocessing\n",
    "\n",
    "The goal here is to clean the query from unnecessary words (such as articles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['éteins', 'télévision']\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def remove_punctuation_and_cap(query: str) -> str:\n",
    "    return query.replace(\",\", \"\").replace(\".\", \"\").lower()\n",
    "            \n",
    "def remove_stopwords(query: str, words: set) -> list:\n",
    "    processed_list = list()\n",
    "    \n",
    "    for word in query.split():\n",
    "        if word not in words:\n",
    "            processed_list.append(word)\n",
    "            \n",
    "    return processed_list\n",
    "\n",
    "def clean_query(query: str, words: set) -> list:\n",
    "    \n",
    "    start = time.time()\n",
    "\n",
    "    query = remove_punctuation_and_cap(query)\n",
    "            \n",
    "    return remove_stopwords(query, words)\n",
    "\n",
    "print(clean_query(\"le elijah, éteins la télévision le le\", [\"elijah\", \"la\", \"le\", \"cette\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to modelize the data ?\n",
    "\n",
    "### Naive representation\n",
    "\n",
    "The data could be modelized as a word list from a query and as a response string. These word lists would be hashed in order to be stored. The hash should have low-dispersion in order for queries to be close to each other when they share the same semantics\n",
    "\n",
    "![](commands-doc/data-storage.svg)\n",
    "\n",
    "### Vectorizing the words\n",
    "\n",
    "Another solution would be to vectorize the words before. With this, we could be able to classify words, which would be quite useful. Classes would represent the answer that the model would give to the user. Thanks to this classification, we could say \"This vector has xx% of chances to match the question\". Database selection could be done with the distance to the barycenter of the topics.\n",
    "\n",
    "![](commands-doc/data-storage2.svg)\n",
    "\n",
    "## Searching\n",
    "\n",
    "### Naive search\n",
    "\n",
    "The easiest version should be to compare query hashes. This is easy to implement but quite inefficient with highly-changing commands. As a consequence, using this search method is not advised as the user would have to put a lot of different commands' aliases when the model could guess what the user wants.\n",
    "\n",
    "### Vector-based search\n",
    "\n",
    "The challenge here is to give a value to each word in order to build a vector. This said vector is going to be transformed in a scalar value with a barycenter computation.\n",
    "\n",
    "#### Naive method\n",
    "\n",
    "We keep each word in memory and assign a random weight to them. When a vector is computed, we look in this table. Consistency is then kept, however, we can't be sure that it is going to be coherent and efficient, especially with new values..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Implementation\n",
    "\n",
    "Those values must be initialized for the words below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "barycenter_list = list()\n",
    "word_map = dict() # map < String, int >\n",
    "\n",
    "known_words = set([\"télévision\", \"allumer\", \"éteindre\"])\n",
    "\n",
    "max_range = 200\n",
    "\n",
    "for word in known_words:\n",
    "    word_map[word] = (random.randrange(-max_range, max_range))/max_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.31\n",
      "0.915\n"
     ]
    }
   ],
   "source": [
    "def valuation(word : str) -> float:\n",
    "    if word in word_map:\n",
    "        return word_map[word]\n",
    "    word_map[word] = (random.randrange(-max_range, max_range))/max_range\n",
    "    return word_map[word]\n",
    "\n",
    "print(valuation(\"télévision\"))\n",
    "print(valuation(\"Poupipou\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each word in the sentence (that has been cleaned), a valuation is associated to it and put in the vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(sentence : list) -> np.array:\n",
    "    v = np.zeros((1, len(sentence)))\n",
    "    \n",
    "    for i, word in enumerate(sentence):\n",
    "        v[0][i] = valuation(word)\n",
    "    \n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# ^ Prevents execution\n",
    "sentence = \"Elijah, allume la télévision\"\n",
    "stoplist = [\"elijah\", \"le\", \"la\"]\n",
    "words = clean_query(sentence, stoplist)\n",
    "\n",
    "\n",
    "v1 = vectorize(clean_query(\"Elijah, allume la télévision\", stoplist))\n",
    "v2 = vectorize(clean_query(\"Elijah, éteins la télévision\", stoplist))\n",
    "v3 = vectorize(clean_query(\"Elijah, allume la télé\", stoplist))\n",
    "v4 = vectorize(clean_query(\"Elijah, éteins la télé\", stoplist))\n",
    "\n",
    "print(np.linalg.norm(v1 - v2))\n",
    "print(np.linalg.norm(v1 - v3))\n",
    "print(np.linalg.norm(v1 - v4))\n",
    "print(np.linalg.norm(v2 - v3))\n",
    "print(np.linalg.norm(v2 - v4))\n",
    "print(np.linalg.norm(v3 - v4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using new rules\n",
    "\n",
    "As expected, since values are chosen randomly, similar words can't be linked together and give values that are very different. \n",
    "In order to link new words with older words, a distance needs to be computed.\n",
    "There are three types of word:\n",
    "- **New words**, that have nothing to do with the others\n",
    "    - These words need to have a random value\n",
    "- **Abreviated words**\n",
    "    - These words must have the same value as the word they represent.\n",
    "- **Alternative words**\n",
    "    - These words need not to change the barycenter of the class they belong.\n",
    "    - To simplify things, alternative words will follow abreviated words' rules.\n",
    "    \n",
    "    \n",
    "##### How to find synonyms ?\n",
    "\n",
    "Usage of a synonym structure (hashed map) and a set of base words\n",
    "\n",
    "![](commands-doc/synonyms.svg)\n",
    "\n",
    "This structure should be filled by an API (synonymes.net ?)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_words = set([\"allumer\", \"éteindre\", \"télévision\"])\n",
    "\n",
    "synonyms_dict = {\n",
    "    \"allumer\": [],\n",
    "    \"éteindre\": [],\n",
    "    \"télévision\": [\"télé\", \"écran\"],\n",
    "    \"télé\": [\"télévision\"],\n",
    "    \"écran\" : [\"télévision\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if the word is an abreviation or a synonym of another. Basically, an abreviate is a synonym. There is no use of the first function anymore, but we'll keep it for the sake of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abreviate(word: str) -> str:\n",
    "    \n",
    "    for ws in set(word_map.keys()):\n",
    "        if word in ws: # if the word is a substring of a key\n",
    "            return ws\n",
    "    \n",
    "    return None\n",
    "\n",
    "def synonym(word: str) -> str: \n",
    "    \n",
    "    if word in base_words:\n",
    "        return word\n",
    "    \n",
    "    if word in set(synonyms_dict.keys()):\n",
    "        return synonyms_dict[word][0]\n",
    "    \n",
    "    # Find possible synonyms here\n",
    "    \n",
    "    # \n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New valuation calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.31\n",
      "-0.31\n",
      "-0.31\n"
     ]
    }
   ],
   "source": [
    "def valuation(word : str) -> float:\n",
    "    if word in word_map: # Word exists\n",
    "        return word_map[word]\n",
    "    \n",
    "    # New word\n",
    "    \n",
    "    abrev = abreviate(word)\n",
    "    syn  = synonym(word)\n",
    "    \n",
    "    if abrev: # The word is a synonym\n",
    "        word_map[word] = word_map[abrev]\n",
    "        return word_map[abrev]\n",
    "        \n",
    "    elif syn: # The word is an abreviation\n",
    "        word_map[word] = word_map[syn]\n",
    "        return word_map[syn]\n",
    "        \n",
    "    # the word is completely new\n",
    "    word_map[word] = random.randrange(-max_range, max_range)\n",
    "    return word_map[word]\n",
    "\n",
    "print(valuation(\"télévision\"))\n",
    "print(valuation(\"télé\"))\n",
    "print(valuation(\"écran\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181.815\n",
      "0.0\n",
      "181.815\n",
      "181.815\n",
      "0.0\n",
      "181.815\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Elijah, allume la télévision\"\n",
    "stoplist = [\"elijah\", \"le\", \"la\"]\n",
    "words = clean_query(sentence, stoplist)\n",
    "\n",
    "\n",
    "v1 = vectorize(clean_query(\"Elijah, allume la télévision\", stoplist))\n",
    "v2 = vectorize(clean_query(\"Elijah, éteins la télévision\", stoplist))\n",
    "v3 = vectorize(clean_query(\"Elijah, allume la télé\", stoplist))\n",
    "v4 = vectorize(clean_query(\"Elijah, éteins la télé\", stoplist))\n",
    "\n",
    "print(np.linalg.norm(v1 - v2))\n",
    "print(np.linalg.norm(v1 - v3))\n",
    "print(np.linalg.norm(v1 - v4))\n",
    "print(np.linalg.norm(v2 - v3))\n",
    "print(np.linalg.norm(v2 - v4))\n",
    "print(np.linalg.norm(v3 - v4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Binding an answer to a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Ok. J'allume la télévision.\": 0.87, \"Ok. J'éteins la télévision.\": 181.0, 'Voici la météo de demain : ': 193.28}\n"
     ]
    }
   ],
   "source": [
    "answers = dict()\n",
    "\n",
    "def bind_vector(sentence_vector : np.array, answers : dict, ans : str):\n",
    "    answers[ans] = np.round(np.linalg.norm(sentence_vector), 2)\n",
    "    \n",
    "def bind_question(question: str, answers : dict, ans : str):\n",
    "    vec = vectorize(clean_query(question, stoplist))\n",
    "    bind_vector(vec, answers, ans)\n",
    "\n",
    "bind_question(\"Allume la télévision\", answers, \"Ok. J'allume la télévision.\")\n",
    "bind_question(\"Éteins la télévision\", answers, \"Ok. J'éteins la télévision.\")\n",
    "bind_question(\"Quelle est la météo de demain ?\", answers, \"Voici la météo de demain : \")\n",
    "\n",
    "print(answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Finding the most fitting answer. \n",
    "\n",
    "We are going to use a priority queue in order to sort the answers by their distance to the query vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pqueue:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.data = list() # (item, priority)\n",
    "    \n",
    "    def add(self, item, priority : float):\n",
    "        l = len(self.data)\n",
    "        \n",
    "        if l == 0:\n",
    "            self.data.insert(0, (item, priority))\n",
    "            return\n",
    "        \n",
    "        for i in range(l):\n",
    "            if self.data[i][1] > priority:\n",
    "                self.data.insert(i, (item, priority))\n",
    "                return\n",
    "                \n",
    "        self.data.insert(l, (item, priority))\n",
    "        \n",
    "    def __str__(self):\n",
    "        s = \"\"\n",
    "        \n",
    "        if len(self.data) == 0:\n",
    "            return \"Empty queue\"\n",
    "        \n",
    "        for item in self.data:\n",
    "            s += str(item) + \" \"\n",
    "        return s\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        return self.data[item]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# pqueue test\n",
    "q = pqueue()\n",
    "q.add(\"hello\", 2)\n",
    "q.add(\"hi\", 4)\n",
    "q.add(\"bonjour\", -1)\n",
    "\n",
    "\n",
    "print(q)\n",
    "\n",
    "del q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"Ok. J'allume la télévision.\", 0.002) (\"Ok. J'éteins la télévision.\", 180.128) ('Voici la météo de demain : ', 192.408) \n",
      "372.538\n"
     ]
    }
   ],
   "source": [
    "def find_answers(query: str, answers : dict) -> (pqueue, float):\n",
    "    q = pqueue()\n",
    "    \n",
    "    v = vectorize(clean_query(query, stoplist))\n",
    "    v = np.round(np.linalg.norm(v) ,3)\n",
    "    \n",
    "    psum = 0\n",
    "    \n",
    "    for ans, barycenter in answers.items():\n",
    "        priority = np.round(abs(barycenter - v), 3)\n",
    "        psum += priority\n",
    "        \n",
    "        q.add(ans, priority)\n",
    "    \n",
    "    return q, psum\n",
    "        \n",
    "result = find_answers(\"Allume la télé\", answers)\n",
    "\n",
    "print(result[0])\n",
    "print(result[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Finding confidence level of each answer\n",
    "It is an indicator to see if the value has chances to be wrong or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
